# Newsfeed

*A FastAPI‚Äëbased news‚Äëaggregation service for corporate IT managers.*
*It features modular ingestion, relevance filtering, and a **************************************relevance¬†√ó¬†recency************************************** scoring pipeline.*

---

## üöÄ Installation

```bash
git clone https://github.com/UmbertoTomasini/newsfeed.git
python3 -m virtualenv newsfeed/venv
source newsfeed/venv/bin/activate
pip install -r newsfeed/requirements.txt
```

> **Tip**‚ÄÇYou never `cd` inside the repo in these commands, so everything works from the directory where you ran the clone.

---

## ‚ñ∂Ô∏è Quick start (local)

> The pipeline first **aggregates IT news** from multiple sources,
> **filters** items relevant to IT managers, then **continuously** fetches new items and rescores them in the background.
> See [Architecture¬†&¬†design](#architecture--design) for the rationale.

### 0‚ÄÇActivate the virtual‚Äëenv (if not already)

```bash
source newsfeed/venv/bin/activate
```

### 1‚ÄÇStart the API server

```bash
uvicorn newsfeed.main:app --reload          # ‚ûú http://127.0.0.1:8000
# Ctrl‚ÄëC to stop
```

Open **[http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)** for Swagger UI.

### 2‚ÄÇTerminal UI¬†‚Äì read the feed

```bash
python -m newsfeed.show_news
```

Items are sorted by **relevance¬†√ó¬†recency**.

### 3‚ÄÇSynthetic ingestion¬†& retrieval (REST)

```bash
# ingest one synthetic item
curl -X POST "http://localhost:8000/ingest" \
  -H "Content-Type: application/json" \
  -d '[
    {
      "id": "outage-aws-us-east-1-20250616",
      "source": "reddit/sysadmin", 
      "title": "AWS US-East-1 Experiencing Major Outage - Multiple Services Down",
      "body": "AWS US-East-1 region is currently experiencing a widespread outage affecting EC2, RDS, and S3 services. The outage started at approximately 14:30 UTC and is impacting thousands of applications. AWS has acknowledged the issue and engineering teams are working on resolution. Customer-facing applications across multiple industries are reporting downtime.",
      "published_at": "2025-06-16T14:30:00Z"
    }
  ]'

# fetch what the filter accepted
curl http://127.0.0.1:8000/retrieve | python3 -m json.tool
```

| Verb   | Path            | Purpose                                                  |
| ------ | --------------- | -------------------------------------------------------- |
| `POST` | `/ingest`       | Push raw items (array)                                   |
| `GET`  | `/retrieve`     | Return *accepted* items, sorted by relevance √ó recency   |
| `GET`  | `/retrieve-all` | Debug: accepted + rejected + evaluation from a large LLM |

---

## üèóÔ∏è Architecture & design

```mermaid
flowchart TD
    sel["Source Selection<br/>NEWS_SOURCES in config.py"] --> src["Aggregation<br/>(Reddit Sysadmin, Reddit Outages, Reddit Cybersec, Ars‚ÄëTechnica, Mock)"]
    src --> mgr["Ingestion Manager"]
    mgr --> hf["Hard Filter<br/>BART-MNLI (zero-shot)"]
    hf --> rec["Recency Weighting<br/>exp(-Œît / PERSISTENCE_TIME)"]
    rec --> mem["In-memory Store<br/>(‚â§ MAX_ITEMS)"]
    subgraph Background
        timer["Background Task Manager<br/>runs every INTERVAL s"] --> mgr
    end
    mem --> api["FastAPI Endpoints"]
    api --> ui["Terminal UI / REST client"]
```

| Stage                       | What happens                                                                                                                                                                                                                                                                                                                                               | Key **config.py** knobs                             |
| --------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------- |
| **Source selection** | Enable/disable data feeds by editing `NEWS_SOURCES` in `config.py`. Each entry chooses a `type` (e.g. `reddit`, `ars_technica`, `mock`) and any params (like `subreddit`). Comment out or remove a row to drop that source without changing code. | `NEWS_SOURCES` |
| **Aggregation**             | Each source fetches `NUMBER_INITIAL_POST_PER_SOURCE` items and normalises them into `NewsItem` objects (`id`, `source`, `title`, `body`, `published_at`, ‚Ä¶).                                                                                                                                                                                               | `NUMBER_INITIAL_POST_PER_SOURCE`, `INTERVAL`        |
| **Ingestion manager**       | Deduplicates on `id`, stamps metadata, pushes batch to filter.                                                                                                                                                                                                                                                                                             | ‚Äî                                                   |
| **Hard filter**             | `facebook/bart‚Äëlarge‚Äëmnli` zero‚Äëshot classifier checks *title¬†+ first 2 sentences* against a specialised label set (see below). Item is accepted if **any** label score ‚â• `MIN_SCORE`. Rejected items are stored *only* when `ASSESS_CORRECTNESS_WITH_BIGGER_MODEL=True`.                                                                                  | `MIN_SCORE`, label list in `ingestion/filtering.py` |
| **Recency weighting**       | Compute `recency_weight = exp(-Œît / PERSISTENCE_TIME)` and save `final_score = relevance_score √ó recency_weight`.                                                                                                                                                                                                                                          | `PERSISTENCE_TIME`                                  |
| **In-memory store**         | Keep accepted items up to `MAX_ITEMS`; older items drop off.                                                                                                                                                                                                                                                                                               | `MAX_ITEMS`                                         |
| **Background Task Manager** | Async loop fetches new items every `INTERVAL` seconds, re‚Äëapplies the filter¬†& scoring.                                                                                                                                                                                                                                                                    | `INTERVAL`                                          |
| **API / UI**                | FastAPI exposes `/ingest`, `/retrieve`, `/retrieve-all`; by default the TUI (`python -m newsfeed.show_news`) calls `/retrieve`, which recomputes recency weights. If `ASSESS_CORRECTNESS_WITH_BIGGER_MODEL=True`, the TUI instead calls `/retrieve-all`, receives *all* items (accepted¬†+¬†rejected) and then performs live evaluation with a larger model. | ‚Äî                                                   |

> **Configuration note**‚ÄÇAll parameters in **CAPS** above live in [`newsfeed/config.py`](newsfeed/config.py). Edit them there to change thresholds, intervals, or feature‚Äëflags.

### Classifier label set & decision rule

| Bucket           | Labels                                                                                                  |
| ---------------- | ------------------------------------------------------------------------------------------------------- |
| **Relevant**     | `Outage`, `Security¬†Incident`, `Vulnerability`, `Major¬†Bug`, *(plus 8¬†more nuanced operational labels)* |
| **Not relevant** | `Not a critical/urgent issue for an IT manager of a company`                                            |

* The label list is intentionally **skewed toward relevant classes** to minimise false‚Äënegatives, which matter more than false‚Äëpositives in this setting.
* The classifier runs in **multi‚Äëlabel** mode (`multi_label=True`). If *any* label‚Äôs probability ‚â• `MIN_SCORE`, the item is accepted; otherwise rejected.
* **Recall¬†/ latency trade‚Äëoff** ‚Äì more labels boost recall but increase inference latency. 

  1. `relevance_score` ‚Üí the *max* label probability.
  2. `top_relevant_label` ‚Üí the label that produced that score.

Rejected items are only persisted when `ASSESS_CORRECTNESS_WITH_BIGGER_MODEL=True` so that a larger model can later reassess them for offline metrics.

---

\*\*‚ÄÇAll parameters in **CAPS** above live in [`newsfeed/config.py`](newsfeed/config.py). Edit them there to change thresholds, intervals, or feature‚Äëflags.

---

## üëì Evaluation of efficiency & correctness (bonus)

### Correctness

Metrics: Precision, Recall and Confusion matrix to measure how many false positives and false/negatives.

1. **Offline metrics (custom dataset)**¬†‚Äì a dataset with 20 examples was created and labelled with **OpenAI¬†o3**¬†stored in `newsfeed/tests/test_cases_relevant.json`¬†.&#x20;

   With `MIN_SCORE = 0.08`, `facebook/bart‚Äëlarge‚Äëmnli` achieves **100‚ÄØ% precision and recall** on this set (see `tests/test_hard_filtering_relevant.py`).
2. **Live evaluation (larger LLM)**¬†‚Äì when `ASSESS_CORRECTNESS_WITH_BIGGER_MODEL=True`, the TUI calls `/retrieve-all` and re‚Äëscores every item with `tiiuae/falcon‚Äë7b‚Äëinstruct` (open‚Äësource, ungated). Falcon‚Äë7B still produces many false‚Äëpositives, worse than `facebook/bart‚Äëlarge‚Äëmnli`¬†.

### Efficiency

* Latency, throughput, CPU and (if present) GPU usage are measured **per pipeline step**.
* Metrics are appended to timestamped files under `logs/efficiency/` when `ASSESS_EFFICIENCY=True` in `config.py`.

---

## üß™ Testing & verification

> **Goal**‚ÄÇGuarantee that the pipeline is correct, reproducible, and fast enough for real‚Äëtime use.

| Test file                               | Kind                       | What it checks                                                                                                                                                                                                   | Command                                           |
| --------------------------------------- | -------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------- |
| `tests/test_aggregation_pipeline.py`    | **Integration**            | ‚Ä¢ Root endpoint 200 OK.‚Ä¢ `/ingest` ACK & items land in memory.‚Ä¢ `/retrieve` orders by recency.‚Ä¢ Dedup prevents duplicate IDs.‚Ä¢ IngestionManager pulls new items from `MockSource` and `/retrieve` reflects them. | `pytest tests/test_aggregation_pipeline.py -q`    |
| `tests/test_efficiency_logging.py`      | **Smoke / Performance**    | ‚Ä¢ Basic 200 responses for `/`, `/retrieve`, `/retrieve-all`.‚Ä¢ `/ingest` ACK round‚Äëtrip.‚Ä¢ Ensures endpoints stay alive when efficiency logging is on.                                                             | `pytest tests/test_efficiency_logging.py -q`      |
| `tests/test_hard_filtering_relevant.py` | **Unit / Offline metrics** | ‚Ä¢ Runs `zero_shot_it_relevance_filter` on a 20‚Äëitem custom dataset.‚Ä¢ Prints confusion matrix, precision, recall; asserts perfect P&R at `MIN_SCORE=0.08`.                                                        | `pytest tests/test_hard_filtering_relevant.py -q` |
| `tests/test_latency.py`                 | **Perf regression**        | ‚Ä¢ Ensures `/ingest`, `/retrieve`, `/retrieve-all` each respond in <¬†500¬†ms on CI runner.‚Ä¢ Fails build if latency budget is exceeded.                                                                             | `pytest tests/test_latency.py -q`                 |

### Coverage & lint helpers

```bash
pytest --cov=newsfeed --cov-report=term-missing   # statement coverage
pre-commit run --all-files                        # Black, isort, Ruff
```

A coverage badge can be added once the project is public:

```md
[![Coverage](https://img.shields.io/badge/coverage-90%25-brightgreen)](#)
```

CI (`.github/workflows/ci.yml`) executes **pytest** (+ coverage) on Python¬†3.10 &¬†3.11 and enforces style via **Black ¬∑ isort ¬∑ Ruff**.

---


## üìù Logging

| Log file folder    | What it captures                                                                                                                                                      | When enabled                                                     |
| ------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------- |
| `logs/items/`      | **Accepted & refused item IDs, titles, sources** plus a tag indicating whether the event happened during the initial startup ingestion or a background refresh cycle. | Always‚Äîwritten by `log_utils` whenever an item decision is made. |
| `logs/efficiency/` | JSON lines with *timestamp, stage name, latency (s), throughput (items/s), CPU %, GPU %*                                                                              | Only when `ASSESS_EFFICIENCY=True` in `config.py`.               |

These logs let you audit relevance decisions and spot performance regressions without rerunning the pipeline.

---

## ‚öôÔ∏è Configuration

| Variable                               | Description                        | Default |
| -------------------------------------- | ---------------------------------- | ------- |
| `NEWS_SOURCES`                         | List of source configs to enable.  | see default list |
| `MIN_SCORE`                            | Minimum relevance score to accept  | `0.08`  |
| `MAX_ITEMS`                            | Max items kept in memory           | `100`   |
| `INTERVAL`                             | Ingestion interval (s)             | `30`    |
| `NUMBER_INITIAL_POST_PER_SOURCE`       | Seed items per source              | `5`     |
| `PERSISTENCE_TIME`                     | Recency decay constant (s)         | `86400` |
| `ASSESS_CORRECTNESS_WITH_BIGGER_MODEL` | Run offline eval with larger model | False   |
| `ASSESS_EFFICIENCY`                    | Log latency & throughput           | `True`  |

See [`newsfeed/config.py`](newsfeed/config.py) for full commentary.

---

## üå± Future work & improvements

### 1¬†Aggregation

- **Per‚Äësource cadence**¬†‚Äì allow `INTERVAL` and `NUMBER_INITIAL_POST_PER_SOURCE` to be overridden per source (e.g. high‚Äëvolume Reddit vs low‚Äëvolume Ars‚ÄëTechnica).
- **Persistent store**¬†‚Äì write accepted items to SQLite so the feed survives restarts and can be queried historically.

### 2¬†Filtering pipeline

- **Richer label set**¬†‚Äì add sub‚Äëlabels for hardware launches, cloud price changes, licence breaches, etc. to boost recall.
- **Fine‚Äëtune BART** ‚Äì curate a dataset by (a) auto‚Äëlabelling fresh feeds with a strong commercial LLM, then human spot‚Äëchecking, or (b) leveraging curated feeds such as Event‚ÄØRegistry, NewsCatcher, Contify, Recorded¬†Future, Flashpoint VulnDB.
- **Curriculum learning**¬†‚Äì start with positive/easy‚Äënegative pairs, then mine *hard negatives* (closest negative item in embedding space) to sharpen the decision boundary.

### 3¬†Composite relevance score

- Plug‚Äëin sentiment, similarity‚Äëto‚Äëpast‚Äëincidents, or vendor‚Äëimpact scores‚Äîeach with its own weight‚Äîso the final ranking reflects business priority, not just recency √ó relevance.

### 4¬†User‚Äëdriven feedback loop

- Let on‚Äëcall engineers up‚Äëvote / down‚Äëvote items in the TUI; feed those signals to a light‚Äëweight online learner that adjusts label thresholds in real time.
- Explore a chat workflow where the model explains *why* an item was classified and asks clarifying questions when unsure.

### 5¬†Performance & evaluation

- Track p95 latency and throughput in CI; fail builds when regressions exceed 20‚ÄØ%.
- Swap Falcon‚Äë7B-Instruct for a distilled model fine‚Äëtuned on the curated dataset above, or a strong commercial model‚Äîexpect higher precision/recall.

---

## üìÑ License

MIT
